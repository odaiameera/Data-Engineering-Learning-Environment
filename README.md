# ðŸš€ Data Engineering Journey | Odai Ameera

Welcome to my professional data engineering portfolio. I am documenting my transition from data analysis to building scalable, high-performance data systems.

![SQL](https://img.shields.io/badge/SQL-PostgreSQL-336791?style=for-the-badge&logo=postgresql&logoColor=white) 
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![AWS](https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white)
![Spark](https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)

```sql
/*
  ---------------------------------------------------------
  -- DATA ENGINEER IN PROGRESS: Odai Ameera
  ---------------------------------------------------------
  
  -- CURRENT STATUS: Building a Modern Data Stack
  -- PRIMARY TOOLS: PostgreSQL, VS Code, Python, PySpark
  -- TARGET ROLES: Data Engineer, Analytics Engineer
*/

-- 1. THE JOURNEY SO FAR
-- Mastering the "Engine Room" of data locally before scaling to the cloud.
-- Moving from raw data analysis to architecting robust ETL pipelines.

SELECT 'Welcome to my Engineering Lab!' AS greeting;

/*
  -- 2. ACCOMPLISHMENTS & CURRENT LEARNING
  -- [x] Google Data Analytics Professional Certificate
  -- [x] Snowflake SQL Introduction
  -- [>] SQL Bootcamp: Go from Zero to Hero (Jose Portilla)
  -- [>] Python Bootcamp: Zero to Hero (Jose Portilla)
  -- [>] Spark and Python for Big Data (Jose Portilla)
  -- [>] AWS Certified Cloud Practitioner CLF-C02 (Stephane Maarek)
  -- [>] AWS Certified Data Engineer Associate (Frank Kane/Stephane Maarek)
  -- [>] IBM Data Engineering Professional Certificate
*/

-- 3. THE ULTIMATE GOAL
-- Designing automated systems that turn raw files (.dat, .csv, .json)
-- into actionable insights within high-performance cloud warehouses.

UPDATE career_path 
SET status = 'Aggressive Learning' 
WHERE goal = 'Professional Data Engineer';

-- 4. TECH TOOLKIT
-- Editor: VS Code (Daily Driver)
-- Database: PostgreSQL, Snowflake
-- Data Processing: PySpark, Pandas
-- Infrastructure: AWS Cloud

/*
  -- "The goal isn't just to see the data, but to build the system that powers it."
*/
